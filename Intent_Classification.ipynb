{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAQ8LqjKfimC"
      },
      "source": [
        "Intent classification with a CLICNIC 150 Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMoKieyUfimD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YXQLogqfimE",
        "outputId": "607b39f6-5669-4524-828e-e37af65802f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nakulhavald/Desktop/ECE/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_PvX6jDfimF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N--mQJKofimF"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTPgbYLOfimF"
      },
      "source": [
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFPCLYNdfimF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('data_full.json') as json_file:\n",
        "    CLINC150 = json.load(json_file)\n",
        "CLINC150_train=CLINC150['train']\n",
        "CLINC150_test=CLINC150['test']\n",
        "CLINC150_val=CLINC150['val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY55VuhffimG",
        "outputId": "b076e011-f550-4ebb-aa82-c3d3ea7b1aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 15000\n",
            "Number of test examples: 4500\n",
            "Number of validation examples: 3000\n"
          ]
        }
      ],
      "source": [
        "# Print the number of examples in each dataset\n",
        "print(\"Number of training examples:\", len(CLINC150_train))\n",
        "print(\"Number of test examples:\", len(CLINC150_test))\n",
        "print(\"Number of validation examples:\", len(CLINC150_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT3fPyDpfimG"
      },
      "outputs": [],
      "source": [
        "classes=['insurance',\n",
        " 'next_holiday',\n",
        " 'repeat',\n",
        " 'credit_limit_change',\n",
        " 'book_hotel',\n",
        " 'yes',\n",
        " 'damaged_card',\n",
        " 'rewards_balance',\n",
        " 'time',\n",
        " 'pto_balance',\n",
        " 'interest_rate',\n",
        " 'change_volume',\n",
        " 'taxes',\n",
        " 'sync_device',\n",
        " 'traffic',\n",
        " 'what_song',\n",
        " 'shopping_list',\n",
        " 'todo_list_update',\n",
        " 'order_checks',\n",
        " 'shopping_list_update']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF4OK_b1fimG"
      },
      "outputs": [],
      "source": [
        "train_data=[]\n",
        "test_data=[]\n",
        "val_data=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq5X6CO8fimG",
        "outputId": "9e772b04-3f63-4560-fdde-557d2cf25a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what time is it in punta gorda, florida</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what time is it in glenwood springs, co</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what time is it in fredericksburg, tx</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what time is it in las vegas, nv</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what time is it in houston, tx</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      text intent\n",
              "0  what time is it in punta gorda, florida   time\n",
              "1  what time is it in glenwood springs, co   time\n",
              "2    what time is it in fredericksburg, tx   time\n",
              "3         what time is it in las vegas, nv   time\n",
              "4           what time is it in houston, tx   time"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for c in CLINC150_train:\n",
        "    if c[1] in classes:\n",
        "        train_data.append(c)\n",
        "for c in CLINC150_test:\n",
        "    if c[1] in classes:\n",
        "        test_data.append(c)\n",
        "for c in CLINC150_val:\n",
        "    if c[1] in classes:\n",
        "        val_data.append(c)\n",
        "df = pd.DataFrame(train_data)\n",
        "df.to_csv('train_data.csv', index=False,header=('text','intent'))\n",
        "train=pd.read_csv('train_data.csv')\n",
        "print(len(train))\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XWSioyJfimG",
        "outputId": "ddc6d686-9579-449b-ac78-f4c588d7b142"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['time', 'shopping_list_update', 'rewards_balance', 'repeat', 'yes',\n",
              "       'insurance', 'todo_list_update', 'sync_device', 'damaged_card',\n",
              "       'next_holiday', 'change_volume', 'what_song', 'book_hotel',\n",
              "       'taxes', 'pto_balance', 'interest_rate', 'credit_limit_change',\n",
              "       'shopping_list', 'traffic', 'order_checks'], dtype=object)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train[\"intent\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0LM-ZCTfimG",
        "outputId": "2403a316-8890-4d26-f547-d67401340e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what time is it in france</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what's the time in london right now</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what hour is it in london</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what's the time</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what is the time in london</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  text intent\n",
              "0            what time is it in france   time\n",
              "1  what's the time in london right now   time\n",
              "2            what hour is it in london   time\n",
              "3                      what's the time   time\n",
              "4           what is the time in london   time"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(val_data)\n",
        "df.to_csv('val_data.csv', index=False,header=('text','intent'))\n",
        "valid=pd.read_csv('val_data.csv')\n",
        "print(len(valid))\n",
        "valid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FA0j9Z_OfimG",
        "outputId": "c28e5d8c-d7c3-44a7-cf8f-ef689cbe6307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "600\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i need you to tell me what time it is in new y...</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what time is it in adelaide, australia right now</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is it after noon</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>is it six o clock yet</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>please give me the time in tanzania at this mo...</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text intent\n",
              "0  i need you to tell me what time it is in new y...   time\n",
              "1   what time is it in adelaide, australia right now   time\n",
              "2                                   is it after noon   time\n",
              "3                              is it six o clock yet   time\n",
              "4  please give me the time in tanzania at this mo...   time"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(test_data)\n",
        "df.to_csv('test_data.csv', index=False,header=('text','intent'))\n",
        "test=pd.read_csv('test_data.csv')\n",
        "print(len(test))\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5RbDqUNfimH"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = pd.concat([train, valid]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMXFrcPgfimH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define model name\n",
        "bert_model_name = \"bert-base-uncased\"\n",
        "\n",
        "# Load tokenizer and model directly from Hugging Face\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
        "model = BertModel.from_pretrained(bert_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6rgbwQ2fimH"
      },
      "source": [
        "Input Text Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAK8oXcpfimH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DataPreparation:\n",
        "\n",
        "    text_column = \"text\"\n",
        "    label_column = \"intent\"\n",
        "\n",
        "    def __init__(self, train, test, classes, max_seq_len=192):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.classes = classes\n",
        "\n",
        "        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self.prepare_data, [train, test])\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        x, y = [], []\n",
        "\n",
        "        for _, row in tqdm(df.iterrows()):\n",
        "            text, label = row[DataPreparation.text_column], row[DataPreparation.label_column]\n",
        "            # Tokenize, add special tokens, and pad to max sequence length\n",
        "            encoding = self.tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,  # Adds [CLS] and [SEP]\n",
        "                max_length=self.max_seq_len,\n",
        "                padding='max_length',  # Pads to max length\n",
        "                truncation=True,  # Truncates to max length\n",
        "                return_tensors=\"np\"  # Returns numpy arrays\n",
        "            )\n",
        "            x.append(encoding['input_ids'][0])\n",
        "            y.append(self.classes.index(label))\n",
        "\n",
        "        return np.array(x), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoptUa_9fimH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DataPreparation:\n",
        "\n",
        "    text_column = \"text\"\n",
        "    label_column = \"intent\"\n",
        "\n",
        "    def __init__(self, train, test, classes, max_seq_len=192):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.classes = classes\n",
        "\n",
        "        # Prepare training and test data\n",
        "        ((self.train_x, self.train_y, self.train_x_attention_mask),\n",
        "         (self.test_x, self.test_y, self.test_x_attention_mask)) = map(self.prepare_data, [train, test])\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        x, y, attention_masks = [], [], []\n",
        "\n",
        "        for _, row in tqdm(df.iterrows()):\n",
        "            text, label = row[DataPreparation.text_column], row[DataPreparation.label_column]\n",
        "\n",
        "            # Tokenize and create attention mask\n",
        "            encoding = self.tokenizer.encode_plus(\n",
        "                text,\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_seq_len,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors=\"np\"\n",
        "            )\n",
        "            x.append(encoding['input_ids'][0])\n",
        "            attention_masks.append(encoding['attention_mask'][0])\n",
        "            y.append(self.classes.index(label))\n",
        "\n",
        "        return np.array(x), np.array(y), np.array(attention_masks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSefS0fhfimH"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2zFpgdofimH"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertModel\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def model_definition(max_seq_len, bert_model_name=\"bert-base-uncased\"):\n",
        "\n",
        "    # Load pre-trained BERT model\n",
        "    bert = TFBertModel.from_pretrained(bert_model_name)\n",
        "\n",
        "    # Define input layer\n",
        "    input_ids = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"input_ids\")\n",
        "    attention_mask = keras.layers.Input(shape=(max_seq_len,), dtype='int32', name=\"attention_mask\")\n",
        "\n",
        "    # Pass inputs through BERT model\n",
        "    bert_output = bert(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Extract the CLS token output\n",
        "    cls_out = bert_output.last_hidden_state[:, 0, :]\n",
        "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
        "\n",
        "    # Add dense layers\n",
        "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
        "    logits = keras.layers.Dropout(0.5)(logits)\n",
        "    logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "\n",
        "    # Define the model with inputs and outputs\n",
        "    model = keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CTq0_lsfimH",
        "outputId": "ae7d0e16-7bbb-4287-fa7b-4fa6e9c81a08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2400it [00:00, 7445.85it/s]\n",
            "600it [00:00, 7575.00it/s]\n"
          ]
        }
      ],
      "source": [
        "# Get the list of unique classes (intents)\n",
        "classes = train['intent'].unique().tolist()\n",
        "\n",
        "# Initialize DataPreparation with updated structure\n",
        "data = DataPreparation(train, test, classes, max_seq_len=128)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e1n8E1BfimH"
      },
      "source": [
        "Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvE42yo8fimH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7g2kyShfimH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "train['intent'] = label_encoder.fit_transform(train['intent'])\n",
        "classes = label_encoder.classes_\n",
        "\n",
        "# Split into train and test sets\n",
        "train_df, val_df = train_test_split(train, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsOwlp3JfimH",
        "outputId": "ec05dd1a-99b7-413e-f596-b062b0ffdb34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['book_hotel', 'change_volume', 'credit_limit_change',\n",
              "       'damaged_card', 'insurance', 'interest_rate', 'next_holiday',\n",
              "       'order_checks', 'pto_balance', 'repeat', 'rewards_balance',\n",
              "       'shopping_list', 'shopping_list_update', 'sync_device', 'taxes',\n",
              "       'time', 'todo_list_update', 'traffic', 'what_song', 'yes'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rq8bHVPyfimH",
        "outputId": "edb8da42-44bb-4698-d446-1414b2e3f767"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>yep, that's true</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1368</th>\n",
              "      <td>how much money do i pay in taxes</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2248</th>\n",
              "      <td>i need a suite that can accommodate 3 adults a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>857</th>\n",
              "      <td>how do i report my card if it got cut in half</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>go now and increase the volume to 4 please</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  intent\n",
              "482                                    yep, that's true      19\n",
              "1368                   how much money do i pay in taxes      14\n",
              "2248  i need a suite that can accommodate 3 adults a...       0\n",
              "857       how do i report my card if it got cut in half       3\n",
              "1017         go now and increase the volume to 4 please       1"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q1UJE5afimI",
        "outputId": "dbb3c0d4-ae08-40f6-a734-e0b104911440"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(240, 2)"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47XepCEfimI"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=128):\n",
        "        self.texts = df['text'].tolist()\n",
        "        self.labels = df['intent'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the input text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Return input IDs, attention mask, and label\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6dQNLEDfimI",
        "outputId": "77c279c1-aea3-4b35-bdc0-0825eaf1bd84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer and model from transformers\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQMDiQlWfimI"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch datasets\n",
        "train_dataset = TextDataset(train_df, tokenizer)\n",
        "val_dataset = TextDataset(val_df, tokenizer)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjG5woZmfimI",
        "outputId": "adb609c9-6900-4301-af01-703c180617d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nakulhavald/Desktop/ECE/myenv/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drw_fUJifimI"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Set up training parameters\n",
        "epochs = 3\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Set up the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, scheduler):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move data to device\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    return total_train_loss / len(data_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def eval_model(model, data_loader):\n",
        "    model.eval()\n",
        "    total_eval_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            # Move data to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Compute accuracy\n",
        "            _, preds = torch.max(outputs.logits, dim=1)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "\n",
        "    avg_eval_loss = total_eval_loss / len(data_loader)\n",
        "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
        "\n",
        "    return avg_eval_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqP1QfApfimI",
        "outputId": "5aaf7ede-d949-4419-a241-e27385d3dbed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "Train loss: 2.633\n",
            "Validation loss: 2.097, Validation accuracy: 0.738\n",
            "Epoch 2/3\n",
            "Train loss: 1.812\n",
            "Validation loss: 1.446, Validation accuracy: 0.950\n",
            "Epoch 3/3\n",
            "Train loss: 1.418\n",
            "Validation loss: 1.253, Validation accuracy: 0.963\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Train the model\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, scheduler)\n",
        "    print(f\"Train loss: {train_loss:.3f}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss, val_acc = eval_model(model, val_loader)\n",
        "    print(f\"Validation loss: {val_loss:.3f}, Validation accuracy: {val_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLBeD7Q8fimI"
      },
      "outputs": [],
      "source": [
        "# Assuming 'test' is your test DataFrame with columns 'text' and 'intent'\n",
        "\n",
        "# Encode the labels in the test dataset\n",
        "test['intent'] = label_encoder.transform(test['intent'])\n",
        "\n",
        "# Create a PyTorch dataset for the test set\n",
        "test_dataset = TextDataset(test, tokenizer)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1n4G5-dfimI"
      },
      "outputs": [],
      "source": [
        "def predict(model, data_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            # Move data to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omb6S1UZfimI",
        "outputId": "a73583e7-b75f-4e64-94dc-40bf37d029b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 94.67%\n"
          ]
        }
      ],
      "source": [
        "test_preds = predict(model, test_loader)\n",
        "\n",
        "# Calculate accuracy using scikit-learn (optional)\n",
        "from sklearn.metrics import accuracy_score\n",
        "test_accuracy = accuracy_score(test['intent'], test_preds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJMRra6jfimJ",
        "outputId": "b93a7a47-2163-4ff3-ad75-26cdae6ef0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: i didn't understand you\n",
            "Actual Intent: repeat\n",
            "Predicted Intent: yes\n",
            "--------------------------------------------------\n",
            "Text: what should i squirrel away to pay in taxes\n",
            "Actual Intent: taxes\n",
            "Predicted Intent: taxes\n",
            "--------------------------------------------------\n",
            "Text: on the way to work is there traffic\n",
            "Actual Intent: traffic\n",
            "Predicted Intent: traffic\n",
            "--------------------------------------------------\n",
            "Text: i need to understand how many points have i earned with my credit card\n",
            "Actual Intent: rewards_balance\n",
            "Predicted Intent: rewards_balance\n",
            "--------------------------------------------------\n",
            "Text: i don't need grocery shopping on my todo list anymore\n",
            "Actual Intent: todo_list_update\n",
            "Predicted Intent: todo_list_update\n",
            "--------------------------------------------------\n",
            "Text: when will my next vacation day be\n",
            "Actual Intent: next_holiday\n",
            "Predicted Intent: next_holiday\n",
            "--------------------------------------------------\n",
            "Text: what time is it in the greenwich timezone\n",
            "Actual Intent: time\n",
            "Predicted Intent: time\n",
            "--------------------------------------------------\n",
            "Text: i want the interest rate for my checking account\n",
            "Actual Intent: interest_rate\n",
            "Predicted Intent: interest_rate\n",
            "--------------------------------------------------\n",
            "Text: i must know how many points have i earned with my credit card\n",
            "Actual Intent: rewards_balance\n",
            "Predicted Intent: rewards_balance\n",
            "--------------------------------------------------\n",
            "Text: what is this song called\n",
            "Actual Intent: what_song\n",
            "Predicted Intent: what_song\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def show_predictions(model, tokenizer, test_df, label_encoder):\n",
        "    # Randomly select 10 samples from the test set\n",
        "    samples = test.sample(n=10).reset_index(drop=True)\n",
        "\n",
        "    # Prepare the texts for prediction\n",
        "    texts = samples['text'].tolist()\n",
        "\n",
        "    # Encode the texts using the tokenizer\n",
        "    encodings = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    # Move tensors to device\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "    # Convert predictions and actual labels to readable format\n",
        "    preds = label_encoder.inverse_transform(preds.cpu().numpy())\n",
        "    actuals = label_encoder.inverse_transform(samples['intent'].values)\n",
        "\n",
        "    # Display the results\n",
        "    for i in range(10):\n",
        "        print(f\"Text: {texts[i]}\")\n",
        "        print(f\"Actual Intent: {actuals[i]}\")\n",
        "        print(f\"Predicted Intent: {preds[i]}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Call the function\n",
        "show_predictions(model, tokenizer, test, label_encoder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDb3RtcXfimJ",
        "outputId": "37874913-c286-468f-8bce-638174f94cf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('model_save/tokenizer_config.json',\n",
              " 'model_save/special_tokens_map.json',\n",
              " 'model_save/vocab.txt',\n",
              " 'model_save/added_tokens.json')"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"model_save\")\n",
        "tokenizer.save_pretrained(\"model_save\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wfBiOt5fimN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcs3LWSqfimN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pWXNOVHfimS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}